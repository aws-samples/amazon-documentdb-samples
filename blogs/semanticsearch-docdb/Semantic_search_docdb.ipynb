{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing necessary libraries\n",
    "!pip3 install pymongo httpx typing pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary libraries\n",
    "import pymongo\n",
    "import json\n",
    "import httpx\n",
    "from typing import List\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a connection to your Amazon DocumentDB (MongoDB compatibility) cluster and creating the database\n",
    "\n",
    "client = pymongo.MongoClient(\n",
    "\"<connection string with port>\",\n",
    "username=\"<username>\",\n",
    "password=\"<password>\",\n",
    "retryWrites=False,\n",
    "tls='true',\n",
    "tlsCAFile=\"global-bundle.pem\")\n",
    "db = client.semanticdemo\n",
    "collection = db.movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the DocumentDB database from the example dataset in csv\n",
    "# Example dataset includes just 50 entries and is adapted from https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "csv_file = \"/home/ec2-user/demomovies.csv\" \n",
    "data = pd.read_csv(csv_file)\n",
    "# Convert the DataFrame to a list of dictionaries (one per row)\n",
    "data_dict = data.to_dict(orient=\"records\")\n",
    "# Insert the data into the DocumentDB collection\n",
    "collection.insert_many(data_dict)\n",
    "print(\"CSV data has been successfully uploaded to DocumentDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating text embeddings and storing it with existing data in Amazon DocumentDB\n",
    "\n",
    "# Defining HuggingFace Token and embedding model\n",
    "hf_token = \"<Put your key from huggingFace's website>\"\n",
    "embedding_url = \"https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "#Define Generate Embedding Function\n",
    "def generate_embedding(text: str) -> List[float]:\n",
    "    client2 = httpx.Client()\n",
    "    response = client2.post(\n",
    "        embedding_url,\n",
    "        headers={\"Authorization\": f\"Bearer {hf_token}\"},\n",
    "        json={\"inputs\": text}\n",
    "    )\n",
    "    client2.close()\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"Request failed with status code {response.status_code}: {response.text}\")\n",
    "    return response.json()\n",
    "\n",
    "# Note: Model can take upto 20 secs to start. So, in case of model error, try again again after 20 seconds.\n",
    "\n",
    "# Fetch all documents that have overview field\n",
    "documents_to_update = list(collection.find({'overview': {\"$exists\": True}}))\n",
    "\n",
    "# Define the batch size for processing\n",
    "batch_size = 10  # You can adjust this based on your requirements\n",
    "\n",
    "# Process documents in batches\n",
    "for i in range(0, len(documents_to_update), batch_size):\n",
    "    batch = documents_to_update[i:i + batch_size]\n",
    "\n",
    "    # Generate embeddings for the current batch and store it alongside existing data as new field\n",
    "    for doc in batch:\n",
    "        doc['embedding_hf'] = generate_embedding(doc['overview'])\n",
    "\n",
    "    # Update the batch of documents\n",
    "    bulk_operations = [pymongo.ReplaceOne({'_id': doc['_id']}, doc) for doc in batch]\n",
    "    collection.bulk_write(bulk_operations)\n",
    "\n",
    "print(\"Batch processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating IVFflat index with dotProduct distance metrics\n",
    "\n",
    "collection.create_index ([(\"embedding_hf\",\"vector\")], vectorOptions={\n",
    "\"lists\": 1,\n",
    "\"similarity\": \"dotProduct\",\n",
    "\"dimensions\": 384})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining which fields in results to project\n",
    "projection = {\n",
    "\"_id\":0,\n",
    "\"title\": 1, \n",
    "\"overview\": 1}\n",
    "\n",
    "#Defining semantic query function\n",
    "def semantic_search(keyword):\n",
    "    query = {\"vectorSearch\" : {\"vector\" : generate_embedding(keyword), \"path\": \"embedding_hf\", \"similarity\": \"dotProduct\", \"k\": 3}}\n",
    "    results = collection.aggregate([{'$search': query},{\"$project\": projection}])\n",
    "    return list(results)\n",
    "\n",
    "#Defining keyword query function\n",
    "def keyword_search(keyword):\n",
    "    results = collection.aggregate([{\"$match\": {\"overview\": {\"$regex\": keyword}}},{\"$project\": projection}])\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing semantic query example - search for movies with words \"young magician\"\n",
    "semantic_search(\"young magician\")\n",
    "\n",
    "#You can see that search results are semantically similar. The query results do not have the exact words \"young magician\". However, it still manages to find movies like Harry Potter. Next, you can compare these results with keyword search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing keyword query example 1 - search for movies with keyword \"young magician\"\n",
    "keyword_search(\"young magician\")\n",
    "\n",
    "#No results were returned because exact words \"young magician\" were not found in the overview description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing keyword query example 2 - search for movies with keyword \"young wizard\"\n",
    "keyword_search(\"young wizard\")\n",
    "\n",
    "#One result was returned because exact words \"young wizard\" were found in the overview description."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
