{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip3.8 install pymongo boto3 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "import pymongo\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a connection to your Amazon DocumentDB (MongoDB compatibility) cluster and creating the database.\n",
    "client = pymongo.MongoClient(\n",
    "\"<Amazon DocumentDB database cluster connection string>\",\n",
    "port=27017,\n",
    "username=\"<username>\",\n",
    "password=\"<password>\",\n",
    "retryWrites=False,\n",
    "tls='true',\n",
    "tlsCAFile=\"/home/ec2-user/global-bundle.pem\") #Check the path as per your destination\n",
    "db = client.semanticdemo\n",
    "collection = db.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a bedrock client. Ensure that you have IAM permissions setup for Bedrock.\n",
    "client = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data has been successfully uploaded to DocumentDB\n"
     ]
    }
   ],
   "source": [
    "# Loading the DocumentDB database from the example dataset in csv\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "csv_file = \"/home/ec2-user/demomovies.csv\" #path to sample database file\n",
    "data = pd.read_csv(csv_file)\n",
    "# Convert the DataFrame to a list of dictionaries (one per row)\n",
    "data_dict = data.to_dict(orient=\"records\")\n",
    "# Insert the data into the MongoDB collection\n",
    "collection.insert_many(data_dict)\n",
    "print(\"CSV data has been successfully uploaded to DocumentDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Bedrock model parameters\n",
    "modelId = \"amazon.titan-embed-text-v1\"  # (Change this to try different embedding models)\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "#Define Generate Embedding Function\n",
    "def generate_embedding(text):\n",
    "    body = json.dumps({\"inputText\": text})\n",
    "    response = client.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    embedding = response_body.get(\"embedding\")\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing completed.\n"
     ]
    }
   ],
   "source": [
    "# Fetch all documents that have overview field\n",
    "documents_to_update = list(collection.find({'overview': {\"$exists\": True}}))\n",
    "\n",
    "# Define the batch size for processing\n",
    "batch_size = 10  # You can adjust this based on your requirements\n",
    "\n",
    "# Process documents in batches\n",
    "for i in range(0, len(documents_to_update), batch_size):\n",
    "    batch = documents_to_update[i:i + batch_size]\n",
    "\n",
    "    # Generate embeddings for the current batch and store it alongside existing data as new field\n",
    "    for doc in batch:\n",
    "        doc['embedding_br'] = generate_embedding(doc['overview'])\n",
    "\n",
    "    # Update the batch of documents\n",
    "    bulk_operations = [pymongo.ReplaceOne({'_id': doc['_id']}, doc) for doc in batch]\n",
    "    collection.bulk_write(bulk_operations)\n",
    "\n",
    "print(\"Batch processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_index'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating HNSW vector search index. You can set the parameters as per your performance and recall requirements.\n",
    "\n",
    "collection.create_index ([(\"embedding_br\",\"vector\")], \n",
    "    vectorOptions= {\n",
    "        \"type\": \"hnsw\", \n",
    "        \"similarity\": \"euclidean\",\n",
    "        \"dimensions\": 1536,\n",
    "        \"m\": 16,\n",
    "        \"efConstruction\": 64},\n",
    "    name=\"my_vss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_text_index'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating native text search index\n",
    "\n",
    "collection.create_index ([(\"overview\",\"text\")],name=\"my_text_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining different query functions\n",
    "\n",
    "#Setting up of projection parameters\n",
    "projection = {\n",
    "\"_id\":0,\n",
    "\"title\": 1, \n",
    "\"overview\": 1}\n",
    "\n",
    "#Semantic search function\n",
    "def search_semantic(keyword):\n",
    "    query = {\"vectorSearch\" : {\"vector\" : generate_embedding(keyword), \"path\": \"embedding_br\", \"similarity\": \"dotProduct\", \"k\": 3}}\n",
    "    results = collection.aggregate([{'$search': query},{\"$project\": projection}])\n",
    "    return list(results)\n",
    "\n",
    "#Text search function\n",
    "def search_text(keyword):\n",
    "    results = collection.aggregate([{\"$match\": {\"$text\": {\"$search\": keyword}}},{\"$project\": projection},{\"$limit\": 3}])\n",
    "    return list(results)\n",
    "\n",
    "#Hybrid query function\n",
    "def search_hybrid(keyword):\n",
    "    results1 = search_semantic(keyword)[:2]\n",
    "    results2 = search_text(keyword)[:2]\n",
    "    combined_results = results1 + results2\n",
    "    combined_results_as_tuples = [tuple(d.items()) for d in combined_results]\n",
    "    union_result = list(set(combined_results_as_tuples))\n",
    "    return union_result[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Rogue One: A Star Wars Story',\n",
       "  'overview': 'A rogue band of resistance fighters unite for a mission to steal the Death Star plans and bring a new hope to the galaxy.'},\n",
       " {'title': 'Avatar',\n",
       "  'overview': 'In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization.'},\n",
       " {'title': 'Ice Age: Continental Drift',\n",
       "  'overview': 'Manny, Diego, and Sid embark upon another adventure after their continent is set adrift. Using an iceberg as a ship, they encounter sea creatures and battle pirates as they explore a new world.'}]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Semantic search function powered by vector search for Amazon DocumentDB captures semantically similar results.\n",
    "#Results includes Star Wars, even though, the overview description does not have word alien.\n",
    "\n",
    "search_semantic(\"aliens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Avatar',\n",
       "  'overview': 'In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization.'},\n",
       " {'title': 'Spider-Man 3',\n",
       "  'overview': 'The seemingly invincible Spider-Man goes up against an all-new crop of villain â€“ including the shape-shifting Sandman. While Spider-Manâ€™s superpowers are altered by an alien organism, his alter ego, Peter Parker, deals with nemesis Eddie Brock and also gets caught up in a love triangle.'}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text search effectively retrieves results where variations of word alien are included. \n",
    "\n",
    "search_text(\"aliens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('title', 'Avatar'),\n",
       "  ('overview',\n",
       "   'In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization.')),\n",
       " (('title', 'Rogue One: A Star Wars Story'),\n",
       "  ('overview',\n",
       "   'A rogue band of resistance fighters unite for a mission to steal the Death Star plans and bring a new hope to the galaxy.')),\n",
       " (('title', 'Spider-Man 3'),\n",
       "  ('overview',\n",
       "   'The seemingly invincible Spider-Man goes up against an all-new crop of villain â€“ including the shape-shifting Sandman. While Spider-Manâ€™s superpowers are altered by an alien organism, his alter ego, Peter Parker, deals with nemesis Eddie Brock and also gets caught up in a love triangle.'))]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hybrid search approach combines the strengths of both semantic and text search methods.\n",
    "#The results includes both Star Wars and Spider-Man. In certain use-cases, combination of vector search and text search would be the best option. \n",
    "\n",
    "search_hybrid(\"aliens\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
