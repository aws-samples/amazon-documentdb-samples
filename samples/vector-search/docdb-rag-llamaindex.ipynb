{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A RAG with Amazon DocumentDB, LlamaIndex and  Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "#!pip3.8 install llama_index.core\n",
    "#!pip3.8 install llama-index llama_index.vector_stores.awsdocdb\n",
    "#!pip3.8 install pymongo \n",
    "#!pip3.8 install llama-index-embeddings-bedrock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "import boto3, pprint\n",
    "from pymongo import MongoClient \n",
    "from llama_index.llms.bedrock import Bedrock\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.awsdocdb import AWSDocDbVectorStore\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.settings import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Bedrock runtime, embedding model and LLM  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating bedrock runtime\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime', region_name='<region name>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining embedding model - amazon.titan-embed-g1-text-02\n",
    "embed_model=BedrockEmbedding(model=\"amazon.titan-embed-g1-text-02\", client=bedrock_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining LLM model - anthropic.claude-instant-v1\n",
    "claude = Bedrock(credentials_profile_name=\"default\", model=\"anthropic.claude-instant-v1\",client=bedrock_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings is a simple singleton object that lives throughout your application. It maintains global settings \n",
    "Settings.llm=claude\n",
    "Settings.embed_model=embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the sample transcript from directory sample-datasets\n",
    "documents = SimpleDirectoryReader(\"./sample-datasets/Q1-2024-result-transcript.pdf\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Connection setup to DocumentDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a connection to your Amazon DocumentDB (MongoDB compatibility) cluster and creating the database\n",
    "docdb_client = MongoClient(\n",
    "\"<Amazon DocumentDB database cluster connection string>\",\n",
    "port=27017,\n",
    "username=\"<username>\",\n",
    "password=\"<password>\",\n",
    "retryWrites=False,\n",
    "tls='true',\n",
    "tlsCAFile=\"/home/ec2-user/SageMaker/global-bundle.pem\") #Change the path as per your destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare collection and database to store embeddings \n",
    "db = docdb_client.ragdemo\n",
    "collection = db.rag\n",
    "collection.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create the vector search index on collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a HNSW vector search index. You can also create an ivfflat index.\n",
    "collection.create_index ([(\"embedding\",\"vector\")], \n",
    "    vectorOptions= {\n",
    "        \"type\": \"hnsw\", \n",
    "        \"similarity\": \"euclidean\",\n",
    "        \"dimensions\": 1536,\n",
    "        \"m\": 16,\n",
    "        \"efConstruction\": 64},\n",
    "    name=\"vector_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking out the data for embedding and create nodes\n",
    "sentence_splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=10)\n",
    "Settings.text_splitter = sentence_splitter\n",
    "nodes= sentence_splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embedding for nodes\n",
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(node.get_content(metadata_mode=\"all\"))\n",
    "    node.embedding = node_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define  the vector store and add the embedding to vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code initialises a DocumentDB Atlas vector store object via the LlamaIndex constructor AWSDocDbVectorStore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding node information with embedding in Amazon Documentdb\n",
    "vector_store =AWSDocDbVectorStore(docdb_client, db_name=\"ragdemo\", collection_name=\"rag\", index_name=\"vector_index\")\n",
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Q&A system on transcript  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intializing index from the vector store for query interfaces\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query engine is a query interface that allows you to ask question over your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting a query engine interface on index\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "query = \"When these results were announced?\"\n",
    "response = query_engine.query(query)\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2\n",
    "query = \"How much was AWS revenue in Q1?\"\n",
    "response = query_engine.query(query)\n",
    "display_response(response)\n",
    "pprint.pprint(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "query = \"what is the Amazon Q?\"\n",
    "response = query_engine.query(query)\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4\n",
    "query = \"What model Bedrock added recently?\"\n",
    "response = query_engine.query(query)\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
